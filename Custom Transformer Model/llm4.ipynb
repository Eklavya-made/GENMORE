{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0c6da55-0c3c-4c2f-868a-37b88d719a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt # for making figures\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1c9be13-6193-4cb8-9f55-a739c0aa581b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toy Story',\n",
       " 'Jumanji',\n",
       " 'Grumpier Old Men',\n",
       " 'Waiting to Exhale',\n",
       " 'Father of the Bride Part II',\n",
       " 'Heat',\n",
       " 'Sabrina',\n",
       " 'Tom and Huck',\n",
       " 'Sudden Death',\n",
       " 'GoldenEye']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = open('movies.txt', 'r', encoding='utf-8').read().splitlines()\n",
    "words[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80b1e3fb-6147-4b69-908d-8cd770fa45b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42259"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e71e6238-35cc-4c9e-96b0-c6f84eecf835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "\n",
    "def clean(word):\n",
    "    word = unicodedata.normalize('NFKD', word)\n",
    "    word = word.lower()\n",
    "    # Keep lowercase letters, digits, spaces, apostrophes, hyphens\n",
    "    word = re.sub(r\"[^a-z0-9 '\\-]\", '', word)\n",
    "    return word.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36ad624a-0030-4807-a414-35698d5d0ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', '@', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '[', ']', '_', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¢', '£', 'ª', '°', '²', '³', '·', '½', '¿', 'À', 'Á', 'Â', 'Å', 'Æ', 'Ç', 'È', 'É', 'Ö', '×', 'Ú', 'Ü', 'ß', 'à', 'á', 'â', 'ã', 'ä', 'å', 'æ', 'ç', 'è', 'é', 'ê', 'ë', 'ì', 'í', 'î', 'ï', 'ð', 'ñ', 'ò', 'ó', 'ô', 'õ', 'ö', 'ø', 'ù', 'ú', 'û', 'ü', 'ā', 'ą', 'Ć', 'ć', 'ē', 'ę', 'ě', 'ğ', 'İ', 'ı', 'ł', 'ń', 'ņ', 'œ', 'ś', 'Ş', 'ş', 'Š', 'š', 'ū', 'ů', 'ż', 'Ž', 'ž', 'Α', 'Β', 'Γ', 'Δ', 'Θ', 'Κ', 'Λ', 'Μ', 'Ν', 'Ξ', 'Ο', 'Π', 'Σ', 'Τ', 'Υ', 'Φ', 'ά', 'έ', 'ή', 'ί', 'α', 'γ', 'δ', 'ε', 'η', 'ι', 'κ', 'λ', 'μ', 'ν', 'ο', 'π', 'ρ', 'ς', 'σ', 'τ', 'υ', 'φ', 'χ', 'ό', 'ύ', 'ώ', 'І', 'А', 'В', 'Г', 'Д', 'Е', 'И', 'К', 'Л', 'М', 'О', 'П', 'С', 'У', 'Х', 'Ш', 'Ю', 'а', 'б', 'в', 'г', 'д', 'е', 'з', 'и', 'й', 'к', 'л', 'м', 'н', 'о', 'п', 'р', 'с', 'т', 'у', 'ф', 'х', 'ц', 'ч', 'ш', 'щ', 'ы', 'ь', 'э', 'ю', 'я', 'ё', 'ا', 'ج', 'س', 'ه', 'چ', 'ک', 'ی', '\\u200e', '–', '‘', '’', '“', '”', '…', '⁴', '№', '™', '⅓', '→', '−', '∞', '☆', '♡', 'ァ', 'ィ', 'ス', 'タ', 'テ', 'フ', 'ポ', 'ン', '傳', '時', '狗', '空', '貓']\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(''.join(words))))\n",
    "print(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22140cfc-f75a-4845-b3b4-e7efda0db12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaned_words = [clean(w) for w in words if w.strip() != '']\n",
    "cleaned_words = [clean(w) for w in words if clean(w).strip() != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02e69b3d-7d17-4dba-99bd-30f552912f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(cleaned_words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66345721-71b0-45d7-b596-be09ce5f1e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " \"'\",\n",
       " '-',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8f37ca5-7825-424b-bd52-d286b96ff6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = sorted(list(set(''.join(cleaned_words))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfad6cf5-f0bf-4cf8-98dd-f014e9806ce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([603369, 3]) torch.Size([603369])\n",
      "torch.Size([77430, 3]) torch.Size([77430])\n",
      "torch.Size([76752, 3]) torch.Size([76752])\n"
     ]
    }
   ],
   "source": [
    "# build the dataset\n",
    "block_size = 3 # context length: how many characters do we take to predict the next one?\n",
    "\n",
    "def build_dataset(cleaned_words):  \n",
    "  X, Y = [], []\n",
    "  \n",
    "  for w in cleaned_words:\n",
    "    context = [0] * block_size\n",
    "    for ch in w + '.':\n",
    "      ix = stoi[ch]\n",
    "      X.append(context)\n",
    "      Y.append(ix)\n",
    "      context = context[1:] + [ix] # crop and append\n",
    "\n",
    "  X = torch.tensor(X)\n",
    "  Y = torch.tensor(Y)\n",
    "  print(X.shape, Y.shape)\n",
    "  return X, Y\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(cleaned_words)\n",
    "n1 = int(0.8*len(cleaned_words))\n",
    "n2 = int(0.9*len(cleaned_words))\n",
    "\n",
    "Xtr,  Ytr  = build_dataset(cleaned_words[:n1])     # 80%\n",
    "Xdev, Ydev = build_dataset(cleaned_words[n1:n2])   # 10%\n",
    "Xte,  Yte  = build_dataset(cleaned_words[n2:])     # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5aba2d8f-cf73-464c-950d-9f4cbc10cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ok biolerplate done, now we get to the action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e8ae3c5-32a4-4b1d-ad93-53e20aed5898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utility function we will use later when comparing manual gradients to PyTorch gradients\n",
    "def cmp(s, dt, t):\n",
    "  ex = torch.all(dt == t.grad).item()\n",
    "  app = torch.allclose(dt, t.grad)\n",
    "  maxdiff = (dt - t.grad).abs().max().item()\n",
    "  print(f'{s:15s} | exact: {str(ex):5s} | approximate: {str(app):5s} | maxdiff: {maxdiff}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa422e91-c770-419c-9b3d-327ab422ae5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5112\n"
     ]
    }
   ],
   "source": [
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 64 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1 # using b1 just for fun, it's useless because of BN\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "# Note: I am initializating many of these parameters in non-standard ways\n",
    "# because sometimes initializating with e.g. all zeros could mask an incorrect\n",
    "# implementation of the backward pass.\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4b93b7d-6073-4d5a-ad7c-5c278653d308",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "n = batch_size # a shorter variable also, for convenience\n",
    "# construct a minibatch\n",
    "ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "df8b104a-5ed6-4463-9671-d6a70d338812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.9876, grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# forward pass, \"chunkated\" into smaller steps that are possible to backward one at a time\n",
    "\n",
    "emb = C[Xb] # embed the characters into vectors\n",
    "embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "# Linear layer 1\n",
    "hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "# BatchNorm layer\n",
    "bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "bndiff = hprebn - bnmeani\n",
    "bndiff2 = bndiff**2\n",
    "bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "bnraw = bndiff * bnvar_inv\n",
    "hpreact = bngain * bnraw + bnbias\n",
    "# Non-linearity\n",
    "h = torch.tanh(hpreact) # hidden layer\n",
    "# Linear layer 2\n",
    "logits = h @ W2 + b2 # output layer\n",
    "# cross entropy loss (same as F.cross_entropy(logits, Yb))\n",
    "logit_maxes = logits.max(1, keepdim=True).values\n",
    "norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "counts = norm_logits.exp()\n",
    "counts_sum = counts.sum(1, keepdims=True)\n",
    "counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "probs = counts * counts_sum_inv\n",
    "logprobs = probs.log()\n",
    "loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# PyTorch backward pass\n",
    "for p in parameters:\n",
    "  p.grad = None\n",
    "for t in [logprobs, probs, counts, counts_sum, counts_sum_inv, # afaik there is no cleaner way\n",
    "          norm_logits, logit_maxes, logits, h, hpreact, bnraw,\n",
    "         bnvar_inv, bnvar, bndiff2, bndiff, hprebn, bnmeani,\n",
    "         embcat, emb]:\n",
    "  t.retain_grad()\n",
    "loss.backward()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b57866f6-4403-4830-ad1e-63922b2329a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logprobs        | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "probs           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum_inv  | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts_sum      | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "counts          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "norm_logits     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logit_maxes     | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "logits          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "h               | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b2              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hpreact         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bngain          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnbias          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnraw           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar_inv       | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnvar           | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff2         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bndiff          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "bnmeani         | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "hprebn          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "embcat          | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "W1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "b1              | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "emb             | exact: True  | approximate: True  | maxdiff: 0.0\n",
      "C               | exact: True  | approximate: True  | maxdiff: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1: backprop through the whole thing manually, \n",
    "# backpropagating through exactly all of the variables \n",
    "# as they are defined in the forward pass above, one by one\n",
    "\n",
    "dlogprobs = torch.zeros_like(logprobs)\n",
    "dlogprobs[range(n), Yb] = -1.0/n\n",
    "dprobs = (1.0 / probs) * dlogprobs\n",
    "dcounts_sum_inv = (counts * dprobs).sum(1, keepdim=True)\n",
    "dcounts = counts_sum_inv * dprobs\n",
    "dcounts_sum = (-counts_sum**-2) * dcounts_sum_inv\n",
    "dcounts += torch.ones_like(counts) * dcounts_sum\n",
    "dnorm_logits = counts * dcounts\n",
    "dlogits = dnorm_logits.clone()\n",
    "dlogit_maxes = (-dnorm_logits).sum(1, keepdim=True)\n",
    "dlogits += F.one_hot(logits.max(1).indices, num_classes=logits.shape[1]) * dlogit_maxes\n",
    "dh = dlogits @ W2.T\n",
    "dW2 = h.T @ dlogits\n",
    "db2 = dlogits.sum(0)\n",
    "dhpreact = (1.0 - h**2) * dh\n",
    "dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "dbnraw = bngain * dhpreact\n",
    "dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "dbndiff = bnvar_inv * dbnraw\n",
    "dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "dbndiff += (2*bndiff) * dbndiff2\n",
    "dhprebn = dbndiff.clone()\n",
    "dbnmeani = (-dbndiff).sum(0)\n",
    "dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "dembcat = dhprebn @ W1.T\n",
    "dW1 = embcat.T @ dhprebn\n",
    "db1 = dhprebn.sum(0)\n",
    "demb = dembcat.view(emb.shape)\n",
    "dC = torch.zeros_like(C)\n",
    "for k in range(Xb.shape[0]):\n",
    "  for j in range(Xb.shape[1]):\n",
    "    ix = Xb[k,j]\n",
    "    dC[ix] += demb[k,j]\n",
    "    \n",
    "cmp('logprobs', dlogprobs, logprobs)\n",
    "cmp('probs', dprobs, probs)\n",
    "cmp('counts_sum_inv', dcounts_sum_inv, counts_sum_inv)\n",
    "cmp('counts_sum', dcounts_sum, counts_sum)\n",
    "cmp('counts', dcounts, counts)\n",
    "cmp('norm_logits', dnorm_logits, norm_logits)\n",
    "cmp('logit_maxes', dlogit_maxes, logit_maxes)\n",
    "cmp('logits', dlogits, logits)\n",
    "cmp('h', dh, h)\n",
    "cmp('W2', dW2, W2)\n",
    "cmp('b2', db2, b2)\n",
    "cmp('hpreact', dhpreact, hpreact)\n",
    "cmp('bngain', dbngain, bngain)\n",
    "cmp('bnbias', dbnbias, bnbias)\n",
    "cmp('bnraw', dbnraw, bnraw)\n",
    "cmp('bnvar_inv', dbnvar_inv, bnvar_inv)\n",
    "cmp('bnvar', dbnvar, bnvar)\n",
    "cmp('bndiff2', dbndiff2, bndiff2)\n",
    "cmp('bndiff', dbndiff, bndiff)\n",
    "cmp('bnmeani', dbnmeani, bnmeani)\n",
    "cmp('hprebn', dhprebn, hprebn)\n",
    "cmp('embcat', dembcat, embcat)\n",
    "cmp('W1', dW1, W1)\n",
    "cmp('b1', db1, b1)\n",
    "cmp('emb', demb, emb)\n",
    "cmp('C', dC, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "53bd80c4-8a38-43da-93bb-5b9f6d619561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.987607002258301 diff: 2.384185791015625e-07\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: backprop through cross_entropy but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the loss,\n",
    "# take the derivative, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# logit_maxes = logits.max(1, keepdim=True).values\n",
    "# norm_logits = logits - logit_maxes # subtract max for numerical stability\n",
    "# counts = norm_logits.exp()\n",
    "# counts_sum = counts.sum(1, keepdims=True)\n",
    "# counts_sum_inv = counts_sum**-1 # if I use (1.0 / counts_sum) instead then I can't get backprop to be bit exact...\n",
    "# probs = counts * counts_sum_inv\n",
    "# logprobs = probs.log()\n",
    "# loss = -logprobs[range(n), Yb].mean()\n",
    "\n",
    "# now:\n",
    "loss_fast = F.cross_entropy(logits, Yb)\n",
    "print(loss_fast.item(), 'diff:', (loss_fast - loss).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ddce4a51-ef52-4078-a10d-55b3d9443fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits          | exact: False | approximate: True  | maxdiff: 8.614733815193176e-09\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "dlogits = F.softmax(logits, 1)\n",
    "dlogits[range(n), Yb] -= 1\n",
    "dlogits /= n\n",
    "\n",
    "cmp('logits', dlogits, logits) # I can only get approximate to be true, my maxdiff is 6e-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6bafada-41b8-45d4-86e6-78443f2d14b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 40]), torch.Size([32]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape, Yb.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2129cb5-376d-4289-a57b-22cced7e5362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0202, 0.0408, 0.0293, 0.0262, 0.0087, 0.0300, 0.0133, 0.0186, 0.0128,\n",
       "        0.0250, 0.0379, 0.0131, 0.0206, 0.0178, 0.0302, 0.0305, 0.0174, 0.0170,\n",
       "        0.0493, 0.0270, 0.0136, 0.0653, 0.0113, 0.0169, 0.0258, 0.0207, 0.0166,\n",
       "        0.0302, 0.0192, 0.0194, 0.0175, 0.0252, 0.0280, 0.0140, 0.0408, 0.0407,\n",
       "        0.0350, 0.0150, 0.0289, 0.0303], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(logits, 1)[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f86bcd0d-f7bd-4825-b469-36758f27e506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0202, -0.9592,  0.0293,  0.0262,  0.0087,  0.0300,  0.0133,  0.0186,\n",
       "         0.0128,  0.0250,  0.0379,  0.0131,  0.0206,  0.0178,  0.0302,  0.0305,\n",
       "         0.0174,  0.0170,  0.0493,  0.0270,  0.0136,  0.0653,  0.0113,  0.0169,\n",
       "         0.0258,  0.0207,  0.0166,  0.0302,  0.0192,  0.0194,  0.0175,  0.0252,\n",
       "         0.0280,  0.0140,  0.0408,  0.0407,  0.0350,  0.0150,  0.0289,  0.0303],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0] * n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5237d823-0907-4584-a288-da7e0438b52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-9.3132e-10, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dlogits[0].sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "533cab06-e760-4529-b122-74edaba8c077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2b78557b500>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(dlogits.detach(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b189da2f-5a8d-4f08-ade0-e7fe18cbc60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max diff: tensor(4.7684e-07, grad_fn=<MaxBackward1>)\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: backprop through batchnorm but all in one go\n",
    "# to complete this challenge look at the mathematical expression of the output of batchnorm,\n",
    "# take the derivative w.r.t. its input, simplify the expression, and just write it out\n",
    "\n",
    "# forward pass\n",
    "\n",
    "# before:\n",
    "# bnmeani = 1/n*hprebn.sum(0, keepdim=True)\n",
    "# bndiff = hprebn - bnmeani\n",
    "# bndiff2 = bndiff**2\n",
    "# bnvar = 1/(n-1)*(bndiff2).sum(0, keepdim=True) # note: Bessel's correction (dividing by n-1, not n)\n",
    "# bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "# bnraw = bndiff * bnvar_inv\n",
    "# hpreact = bngain * bnraw + bnbias\n",
    "\n",
    "# now:\n",
    "hpreact_fast = bngain * (hprebn - hprebn.mean(0, keepdim=True)) / torch.sqrt(hprebn.var(0, keepdim=True, unbiased=True) + 1e-5) + bnbias\n",
    "print('max diff:', (hpreact_fast - hpreact).abs().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a606e19c-3256-40d1-a7c6-56f3ce6e2a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hprebn          | exact: False | approximate: True  | maxdiff: 9.313225746154785e-10\n"
     ]
    }
   ],
   "source": [
    "# backward pass\n",
    "\n",
    "# before we had:\n",
    "# dbnraw = bngain * dhpreact\n",
    "# dbndiff = bnvar_inv * dbnraw\n",
    "# dbnvar_inv = (bndiff * dbnraw).sum(0, keepdim=True)\n",
    "# dbnvar = (-0.5*(bnvar + 1e-5)**-1.5) * dbnvar_inv\n",
    "# dbndiff2 = (1.0/(n-1))*torch.ones_like(bndiff2) * dbnvar\n",
    "# dbndiff += (2*bndiff) * dbndiff2\n",
    "# dhprebn = dbndiff.clone()\n",
    "# dbnmeani = (-dbndiff).sum(0)\n",
    "# dhprebn += 1.0/n * (torch.ones_like(hprebn) * dbnmeani)\n",
    "\n",
    "# calculate dhprebn given dhpreact (i.e. backprop through the batchnorm)\n",
    "# (you'll also need to use some of the variables from the forward pass up above)\n",
    "\n",
    "dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "\n",
    "cmp('hprebn', dhprebn, hprebn) # I can only get approximate to be true, my maxdiff is 9e-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cb44ecbf-f59f-41d2-bba6-e2a94e74de6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([32, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([1, 64]),\n",
       " torch.Size([32, 64]),\n",
       " torch.Size([64]))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhprebn.shape, bngain.shape, bnvar_inv.shape, dbnraw.shape, dbnraw.sum(0).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "44b149c0-4c8e-4cfe-9c13-a3cf91197d32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15040\n",
      "      0/ 200000: 4.2333\n",
      "  10000/ 200000: 2.5793\n",
      "  20000/ 200000: 2.1308\n",
      "  30000/ 200000: 2.4875\n",
      "  40000/ 200000: 2.2450\n",
      "  50000/ 200000: 1.9684\n",
      "  60000/ 200000: 2.2979\n",
      "  70000/ 200000: 2.4172\n",
      "  80000/ 200000: 2.1559\n",
      "  90000/ 200000: 1.6116\n",
      " 100000/ 200000: 2.1135\n",
      " 110000/ 200000: 1.7015\n",
      " 120000/ 200000: 2.1581\n",
      " 130000/ 200000: 2.1449\n",
      " 140000/ 200000: 2.0425\n",
      " 150000/ 200000: 1.6956\n",
      " 160000/ 200000: 2.0517\n",
      " 170000/ 200000: 2.2551\n",
      " 180000/ 200000: 2.3606\n",
      " 190000/ 200000: 1.8775\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: putting it all together!\n",
    "# Train the MLP neural net with your own backward pass\n",
    "\n",
    "# init\n",
    "n_embd = 10 # the dimensionality of the character embedding vectors\n",
    "n_hidden = 200 # the number of neurons in the hidden layer of the MLP\n",
    "\n",
    "g = torch.Generator().manual_seed(2147483647) # for reproducibility\n",
    "C  = torch.randn((vocab_size, n_embd),            generator=g)\n",
    "# Layer 1\n",
    "W1 = torch.randn((n_embd * block_size, n_hidden), generator=g) * (5/3)/((n_embd * block_size)**0.5)\n",
    "b1 = torch.randn(n_hidden,                        generator=g) * 0.1\n",
    "# Layer 2\n",
    "W2 = torch.randn((n_hidden, vocab_size),          generator=g) * 0.1\n",
    "b2 = torch.randn(vocab_size,                      generator=g) * 0.1\n",
    "# BatchNorm parameters\n",
    "bngain = torch.randn((1, n_hidden))*0.1 + 1.0\n",
    "bnbias = torch.randn((1, n_hidden))*0.1\n",
    "\n",
    "parameters = [C, W1, b1, W2, b2, bngain, bnbias]\n",
    "print(sum(p.nelement() for p in parameters)) # number of parameters in total\n",
    "for p in parameters:\n",
    "  p.requires_grad = True\n",
    "\n",
    "# same optimization as last time\n",
    "max_steps = 200000\n",
    "batch_size = 32\n",
    "n = batch_size # convenience\n",
    "lossi = []\n",
    "\n",
    "# use this context manager for efficiency once your backward pass is written (TODO)\n",
    "with torch.no_grad():\n",
    "\n",
    "  # kick off optimization\n",
    "  for i in range(max_steps):\n",
    "\n",
    "    # minibatch construct\n",
    "    ix = torch.randint(0, Xtr.shape[0], (batch_size,), generator=g)\n",
    "    Xb, Yb = Xtr[ix], Ytr[ix] # batch X,Y\n",
    "\n",
    "    # forward pass\n",
    "    emb = C[Xb] # embed the characters into vectors\n",
    "    embcat = emb.view(emb.shape[0], -1) # concatenate the vectors\n",
    "    # Linear layer\n",
    "    hprebn = embcat @ W1 + b1 # hidden layer pre-activation\n",
    "    # BatchNorm layer\n",
    "    # -------------------------------------------------------------\n",
    "    bnmean = hprebn.mean(0, keepdim=True)\n",
    "    bnvar = hprebn.var(0, keepdim=True, unbiased=True)\n",
    "    bnvar_inv = (bnvar + 1e-5)**-0.5\n",
    "    bnraw = (hprebn - bnmean) * bnvar_inv\n",
    "    hpreact = bngain * bnraw + bnbias\n",
    "    # -------------------------------------------------------------\n",
    "    # Non-linearity\n",
    "    h = torch.tanh(hpreact) # hidden layer\n",
    "    logits = h @ W2 + b2 # output layer\n",
    "    loss = F.cross_entropy(logits, Yb) # loss function\n",
    "\n",
    "    # backward pass\n",
    "    for p in parameters:\n",
    "      p.grad = None\n",
    "    #loss.backward() # use this for correctness comparisons, delete it later!\n",
    "\n",
    "    # manual backprop! #swole_doge_meme\n",
    "    # -----------------\n",
    "    dlogits = F.softmax(logits, 1)\n",
    "    dlogits[range(n), Yb] -= 1\n",
    "    dlogits /= n\n",
    "    # 2nd layer backprop\n",
    "    dh = dlogits @ W2.T\n",
    "    dW2 = h.T @ dlogits\n",
    "    db2 = dlogits.sum(0)\n",
    "    # tanh\n",
    "    dhpreact = (1.0 - h**2) * dh\n",
    "    # batchnorm backprop\n",
    "    dbngain = (bnraw * dhpreact).sum(0, keepdim=True)\n",
    "    dbnbias = dhpreact.sum(0, keepdim=True)\n",
    "    dhprebn = bngain*bnvar_inv/n * (n*dhpreact - dhpreact.sum(0) - n/(n-1)*bnraw*(dhpreact*bnraw).sum(0))\n",
    "    # 1st layer\n",
    "    dembcat = dhprebn @ W1.T\n",
    "    dW1 = embcat.T @ dhprebn\n",
    "    db1 = dhprebn.sum(0)\n",
    "    # embedding\n",
    "    demb = dembcat.view(emb.shape)\n",
    "    dC = torch.zeros_like(C)\n",
    "    for k in range(Xb.shape[0]):\n",
    "      for j in range(Xb.shape[1]):\n",
    "        ix = Xb[k,j]\n",
    "        dC[ix] += demb[k,j]\n",
    "    grads = [dC, dW1, db1, dW2, db2, dbngain, dbnbias]\n",
    "    # -----------------\n",
    "\n",
    "    # update\n",
    "    lr = 0.1 if i < 100000 else 0.01 # step learning rate decay\n",
    "    for p, grad in zip(parameters, grads):\n",
    "      #p.data += -lr * p.grad # old way of cheems doge (using PyTorch grad from .backward())\n",
    "      p.data += -lr * grad # new way of swole doge TODO: enable\n",
    "\n",
    "    # track stats\n",
    "    if i % 10000 == 0: # print every once in a while\n",
    "      print(f'{i:7d}/{max_steps:7d}: {loss.item():.4f}')\n",
    "    lossi.append(loss.log10().item())\n",
    "\n",
    "  #   if i >= 100: # TODO: delete early breaking when you're ready to train the full net\n",
    "  #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e2d6127-7841-4d5d-af0a-92c0b80fc875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calibrate the batch norm at the end of training\n",
    "\n",
    "with torch.no_grad():\n",
    "  # pass the training set through\n",
    "  emb = C[Xtr]\n",
    "  embcat = emb.view(emb.shape[0], -1)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  # measure the mean/std over the entire training set\n",
    "  bnmean = hpreact.mean(0, keepdim=True)\n",
    "  bnvar = hpreact.var(0, keepdim=True, unbiased=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b15d31b8-dd32-4179-ba23-78aeff303b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 2.0163753032684326\n",
      "val 2.03381085395813\n"
     ]
    }
   ],
   "source": [
    "# evaluate train and val loss\n",
    "\n",
    "@torch.no_grad() # this decorator disables gradient tracking\n",
    "def split_loss(split):\n",
    "  x,y = {\n",
    "    'train': (Xtr, Ytr),\n",
    "    'val': (Xdev, Ydev),\n",
    "    'test': (Xte, Yte),\n",
    "  }[split]\n",
    "  emb = C[x] # (N, block_size, n_embd)\n",
    "  embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "  hpreact = embcat @ W1 + b1\n",
    "  hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "  h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "  logits = h @ W2 + b2 # (N, vocab_size)\n",
    "  loss = F.cross_entropy(logits, y)\n",
    "  print(split, loss.item())\n",
    "\n",
    "split_loss('train')\n",
    "split_loss('val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e7a4560-edee-4b68-880a-682866800b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ter is lammers.\n",
      "iachell beyine.\n",
      "grace nunphones.\n",
      "graventuret hight way a fince.\n",
      "the secta.\n",
      "fightertine night.\n",
      "texadaychards of the in pland the fing fours.\n",
      "liferly.\n",
      "the vidhakharouse and get.\n",
      "afishtpo.\n",
      "the wevoluble faminnister glastand of dred.\n",
      "roirictoje man requalt.\n",
      "can bam for gyanking pich.\n",
      "on tew conningk frots.\n",
      "primsun legasire tery.\n",
      "vitchilesd.\n",
      "ss fack stings.\n",
      "cock stone in the retate summerimarnan danema.\n",
      "plirts playatreen.\n",
      "1ston the nighter of nesc.\n"
     ]
    }
   ],
   "source": [
    "# sample from the model\n",
    "g = torch.Generator().manual_seed(2147483647 + 10)\n",
    "\n",
    "for _ in range(20):\n",
    "    \n",
    "    out = []\n",
    "    context = [0] * block_size # initialize with all ...\n",
    "    while True:\n",
    "      # ------------\n",
    "      # forward pass:\n",
    "      # Embedding\n",
    "      emb = C[torch.tensor([context])] # (1,block_size,d)      \n",
    "      embcat = emb.view(emb.shape[0], -1) # concat into (N, block_size * n_embd)\n",
    "      hpreact = embcat @ W1 + b1\n",
    "      hpreact = bngain * (hpreact - bnmean) * (bnvar + 1e-5)**-0.5 + bnbias\n",
    "      h = torch.tanh(hpreact) # (N, n_hidden)\n",
    "      logits = h @ W2 + b2 # (N, vocab_size)\n",
    "      # ------------\n",
    "      # Sample\n",
    "      probs = F.softmax(logits, dim=1)\n",
    "      ix = torch.multinomial(probs, num_samples=1, generator=g).item()\n",
    "      context = context[1:] + [ix]\n",
    "      out.append(ix)\n",
    "      if ix == 0:\n",
    "        break\n",
    "    \n",
    "    print(''.join(itos[i] for i in out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10536da0-d2e6-4eb3-b9aa-987781f28f09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
